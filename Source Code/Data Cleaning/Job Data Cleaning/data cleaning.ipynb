{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ad04d54-e333-4623-bcf8-b915b1a835ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9538e48e-99cd-438f-be3d-da74d4b9c2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique technologies: 7251\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"Final_mapped_keywords_mapped.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Collect all unique technologies, skipping null/empty\n",
    "tech_set = set()\n",
    "for entry in data:\n",
    "    technologies = entry.get(\"Technologies\")\n",
    "    if technologies:\n",
    "        tech_set.update(technologies)\n",
    "\n",
    "# Convert to a sorted list\n",
    "terms = sorted(tech_set)\n",
    "print(f\"Total unique technologies: {len(terms)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10065acb-2517-461a-82bd-3efdd8b3901f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out 0 empty‐norm terms; remaining 7251\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def normalize(term: str) -> str:\n",
    "    t = term.lower()\n",
    "    t = re.sub(r\"[^a-z0-9 ]+\", \" \", t)  \n",
    "    t = re.sub(r\"\\s+\", \" \", t)           \n",
    "    return t.strip()\n",
    "\n",
    "# Normalize all terms\n",
    "normed = [normalize(t) for t in terms]\n",
    "\n",
    "# Filter out any terms that normalize to an empty string\n",
    "filtered = [(orig, n) for orig, n in zip(terms, normed) if n]\n",
    "terms_filt, normed_filt = zip(*filtered)\n",
    "\n",
    "print(f\"Filtered out {len(terms) - len(terms_filt)} empty‐norm terms; remaining {len(terms_filt)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f356e1b-9f72-4a42-a758-4293dfff432e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF‑IDF matrix shape: (7251, 5019)\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the filtered normalized strings with TF‑IDF\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(normed_filt)\n",
    "\n",
    "print(\"TF‑IDF matrix shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6b479c3-5cb0-4bdc-bf5d-2b88c17d8996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out 14 zero‑vector terms; clustering on 7237 terms\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "row_nnz = X.getnnz(axis=1)\n",
    "mask = row_nnz > 0\n",
    "zero_count = np.sum(~mask)\n",
    "print(f\"Filtered out {zero_count} zero‑vector terms; clustering on {mask.sum()} terms\")\n",
    "\n",
    "\n",
    "terms_cluster = [terms_filt[i]    for i in range(len(terms_filt))    if mask[i]]\n",
    "normed_cluster = [normed_filt[i]   for i in range(len(normed_filt))   if mask[i]]\n",
    "X_cluster      = X[mask].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2c8666-6cb9-4d1b-919d-b95792a28da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "clusterer = AgglomerativeClustering(\n",
    "    n_clusters=None,\n",
    "    metric=\"cosine\",       \n",
    "    linkage=\"average\",\n",
    "    distance_threshold=0.8  \n",
    ")\n",
    "labels = clusterer.fit_predict(X_cluster)\n",
    "\n",
    "print(f\"Found {labels.max() + 1} clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "070eaf7f-a0af-4968-9e22-efbacf24d60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  'Firebase Realtime Database' → Firebase Realtime Database\n",
      "  'Python scripts'              → None\n"
     ]
    }
   ],
   "source": [
    "# Chunk 6: Build the canonical mapping, including zero‑vector terms\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# Group clustered terms by label\n",
    "clusters = defaultdict(list)\n",
    "for term, lbl, norm in zip(terms_cluster, labels, normed_cluster):\n",
    "    clusters[lbl].append((term, norm))\n",
    "\n",
    "# Map each original to its cluster representative\n",
    "canonical = {}\n",
    "for lbl, members in clusters.items():\n",
    "    rep = min(members, key=lambda x: len(x[1]))[0]\n",
    "    for orig, _ in members:\n",
    "        canonical[orig] = rep\n",
    "\n",
    "# For zero-vector terms, map them to themselves\n",
    "for orig in terms_filt:\n",
    "    if orig not in canonical:\n",
    "        canonical[orig] = orig\n",
    "\n",
    "# Example sanity checks\n",
    "print(\"  'Firebase Realtime Database' →\", canonical.get(\"Firebase Realtime Database\"))\n",
    "print(\"  'Python scripts'              →\", canonical.get(\"Python scripts\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b5ca60-fc0d-4a8f-aa12-2ffc05b39093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Build a DataFrame of Original, Normalized, and Canonical columns\n",
    "records = []\n",
    "for orig in terms_filt:\n",
    "    records.append({\n",
    "        \"Original Term\": orig,\n",
    "        \"Normalized\": normalize(orig),\n",
    "        \"Canonical\": canonical.get(orig, orig)\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Write out to Excel\n",
    "out_path = \"tech_mapping_threshold_0.8.xlsx\"\n",
    "df.to_excel(out_path, index=False)\n",
    "\n",
    "print(f\"Wrote mapping to {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10a4bb1-4882-40c7-8450-648cfa5a8de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "excel_path = \"tech_mapping_threshold_0.8.xlsx\"\n",
    "df_map = pd.read_excel(excel_path)\n",
    "\n",
    "# Original Term → Canonical\n",
    "mapping = dict(zip(df_map[\"Original Term\"], df_map[\"Canonical\"]))\n",
    "\n",
    "with open(\"Final_mapped_keywords_mapped.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for entry in data:\n",
    "    techs = entry.get(\"Technologies\")\n",
    "    if techs:\n",
    "        entry[\"Technologies\"] = [mapping.get(t, t) for t in techs]\n",
    "\n",
    "# Save out the cleaned JSON\n",
    "out_path = \"Clusted_technologies_keywords.json\"\n",
    "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Wrote clustered/cleaned file to {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09ea435-7053-4698-a7c5-c67ab941b6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"Clusted_technologies_keywords.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Collect all unique technologies\n",
    "tech_set = set()\n",
    "for entry in data:\n",
    "    technologies = entry.get(\"Technologies\") or []\n",
    "    tech_set.update(technologies)\n",
    "\n",
    "print(f\"Total unique technologies: {len(tech_set)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
